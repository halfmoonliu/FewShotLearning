{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments of Linear Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import internal sources (from github)\n",
    "from src.transformer import Transformer\n",
    "from src.data import create_weights\n",
    "from src.config import config\n",
    "from src.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "num_seeds = 1\n",
    "num_layers = 1\n",
    "\n",
    "config.num_seeds = num_seeds\n",
    "config.analyse = True\n",
    "config.seed = 0\n",
    "\n",
    "config.in_proj = False\n",
    "config.adam = True\n",
    "config.dataset_size = 10\n",
    "config.input_size = 10\n",
    "config.num_layers = num_layers\n",
    "config.input_range = 1\n",
    "\n",
    "\n",
    "if config.num_layers == 1:\n",
    "  assert config.deq == True\n",
    "  assert config.gd_deq == True\n",
    "\n",
    "if config.num_layers > 1:\n",
    "  assert config.y_update == False\n",
    "\n",
    "config.distract_size = 0\n",
    "config.training_steps_gd = 5#1000 if config.gd_deq else 30000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Lists\n",
    "\n",
    "loss_trans_list =  [[]  for _ in range(config.num_seeds)]\n",
    "loss_trans_train_list =  [[]  for _ in range(config.num_seeds)]\n",
    "losses_gd_list =  [[]  for _ in range(config.num_seeds)]\n",
    "losses_gd_list_trained =  [[]  for _ in range(config.num_seeds)]\n",
    "losses_int_list_trained =  [[]  for _ in range(config.num_seeds)]\n",
    "cos_sim_list, cos_sim_list_o =  [[]  for _ in range(config.num_seeds)],  [[]  for _ in range(config.num_seeds)]\n",
    "grad_norm_list, grad_norm_list_o =  [[]  for _ in range(config.num_seeds)],  [[]  for _ in range(config.num_seeds)]\n",
    "p_norm_list, p_norm_list_o =  [[]  for _ in range(config.num_seeds)],  [[]  for _ in range(config.num_seeds)]\n",
    "\n",
    "cos_sim_list, cos_sim_list_o =  [[]  for _ in range(config.num_seeds)],  [[]  for _ in range(config.num_seeds)]\n",
    "grad_norm_list, grad_norm_list_o =  [[]  for _ in range(config.num_seeds)],  [[]  for _ in range(config.num_seeds)]\n",
    "p_norm_list, p_norm_list_o =  [[]  for _ in range(config.num_seeds)],  [[]  for _ in range(config.num_seeds)]\n",
    "\n",
    "ir_t_list = [[]  for _ in range(config.num_seeds)]\n",
    "ws_t_list = [[]  for _ in range(config.num_seeds)]\n",
    "ir_gd_list = [[]  for _ in range(config.num_seeds)]\n",
    "ws_gd_list = [[]  for _ in range(config.num_seeds)]\n",
    "\n",
    "ir_t_ood_list = [[]  for _ in range(config.num_seeds)]\n",
    "ws_t_ood_list = [[]  for _ in range(config.num_seeds)]\n",
    "ir_gd_ood_list = [[]  for _ in range(config.num_seeds)]\n",
    "ws_gd_ood_list = [[]  for _ in range(config.num_seeds)]\n",
    "\n",
    "ir_gd_trained_list = [[]  for _ in range(config.num_seeds)]\n",
    "ws_gd_trained_list = [[]  for _ in range(config.num_seeds)]\n",
    "ir_gd_ood_trained_list = [[]  for _ in range(config.num_seeds)]\n",
    "ws_gd_ood_trained_list = [[]  for _ in range(config.num_seeds)]\n",
    "\n",
    "ir_inter_list = [[]  for _ in range(config.num_seeds)]\n",
    "ws_inter_list = [[]  for _ in range(config.num_seeds)]\n",
    "ir_inter_ood_list = [[]  for _ in range(config.num_seeds)]\n",
    "ws_inter_ood_list = [[]  for _ in range(config.num_seeds)]\n",
    "\n",
    "\n",
    "losses_noisy_list = [[]  for _ in range(config.num_seeds)]\n",
    "losses_gd_noisy_list = [[]  for _ in range(config.num_seeds)]\n",
    "losses_gd_noisy_trained_list = [[]  for _ in range(config.num_seeds)]\n",
    "losses_inter_noisy_list = [[]  for _ in range(config.num_seeds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Logic how to interpolate weights\n",
    "def interpolate_weights(train_state, params_gd, deq=False):\n",
    "  if (config.num_heads == 1 and \n",
    "      config.sum_norm == False and config.deq == True and\n",
    "      config.layer_norm == False and config.att_only_trans == True):\n",
    "\n",
    "    cur_train_params = {k.replace('transformer', 'Transformer_gd'):v.copy() for \n",
    "                    k,v in train_state.params.items()}\n",
    "\n",
    "    inter_params = {k.replace('transformer', 'Transformer_gd'): {'w': jnp.zeros_like(v['w'])} for \n",
    "                    k,v in train_state.params.items()}\n",
    "\n",
    "    for k,v in cur_train_params.items():\n",
    "      if \"key\" in k:\n",
    "        key_gd  = params_gd[k]['w'].copy() \n",
    "        key  = cur_train_params[k]['w'].copy()\n",
    "      if \"linear\" in k:\n",
    "        linear_gd = params_gd[k]['w'].copy() \n",
    "        linear = cur_train_params[k]['w'].copy() \n",
    "      if \"query\" in k:\n",
    "        query_gd = params_gd[k]['w'].copy() \n",
    "        query = cur_train_params[k]['w'].copy() \n",
    "      if \"value\" in k:\n",
    "        value_gd = params_gd[k]['w'].copy() \n",
    "        value = cur_train_params[k]['w'].copy()        \n",
    "        \n",
    "        query = jnp.matmul(query, key.T)\n",
    "        #print(query)\n",
    "        key = jnp.identity(query.shape[0])\n",
    "        mean = np.mean([query[a, a] for a in range(query.shape[0]-1)])\n",
    "        query = query/mean\n",
    "        query_gd = jnp.matmul(query_gd, key.T)\n",
    "        key_gd = jnp.identity(query.shape[0])\n",
    "        query = (query + query_gd)/2\n",
    "\n",
    "        linear = jnp.matmul(value, linear)\n",
    "        #print(linear)\n",
    "        value = jnp.identity(query.shape[0])\n",
    "        linear = linear*mean\n",
    "        linear_gd = jnp.matmul(value_gd, linear_gd)\n",
    "        value_gd = jnp.identity(query.shape[0])\n",
    "        linear = (linear + linear_gd)/2    \n",
    "\n",
    "        inter_params[k.replace('value', 'linear')]['w'] = linear\n",
    "        inter_params[k.replace('value', 'value')]['w'] = value\n",
    "        inter_params[k.replace('value', 'query')]['w'] = query\n",
    "        inter_params[k.replace('value', 'key')]['w'] = key\n",
    "\n",
    "    losses_int, _, _ = predict_test.apply(inter_params, eval_rng, eval_data, True)\n",
    "  else:\n",
    "    losses_int = None\n",
    "    inter_params = None\n",
    "  return losses_int, inter_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Create datasets\n",
    "\n",
    "\"\"\"Data utils.\n",
    "  Provide functions to create regression datasets.\n",
    "\"\"\"\n",
    "\n",
    "from functools import partial\n",
    "import jax\n",
    "from jax import vmap\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(1, 2, 3))\n",
    "def create_data_normal(rng, i_size, c_size, size_distract, input_range, w_scale):\n",
    "  \"\"\"Create a linear regression data set: X*w where x ~ N(0, 1), w ~ N(1,1).\"\"\"\n",
    "\n",
    "  rng, new_rng, new_rng2, new_rng3, new_rng4 = jax.random.split(rng, 5)\n",
    "  w = 1 + jax.random.normal(rng, shape=[i_size])*w_scale\n",
    "  x = jax.random.normal(new_rng, shape=[c_size, i_size])*w_scale\n",
    "  x_querry = jax.random.normal(new_rng2, shape=[1, i_size])*w_scale\n",
    "\n",
    "  y_data = jnp.squeeze(x@w)\n",
    "\n",
    "  y_target = x_querry@w\n",
    "  y_target = y_target[..., None]\n",
    "\n",
    "\n",
    "  seq = jnp.concatenate([x, y_data[..., None]], -1)\n",
    "  target = jnp.concatenate([x_querry, y_target], -1)\n",
    "  x_querry_init = -1*x_querry.dot(jnp.ones_like(x_querry).T*0.0)\n",
    "  zero = jnp.concatenate([x_querry, x_querry_init], -1)\n",
    "  seq = jnp.concatenate([seq, zero], 0)\n",
    "  return jnp.squeeze(seq), jnp.squeeze(target), w\n",
    "\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(1, 2, 3))\n",
    "def create_data_normal_noisy(rng, i_size, c_size, size_distract, input_range, eps_sigma):\n",
    "  \"\"\"Create a linear regression data set: X*w where x ~ N(0, 1), w ~ N(1,1) eps ~ N(0, eps_sigma).\"\"\"\n",
    "\n",
    "  rng, new_rng, new_rng2, new_rng3, new_rng4 = jax.random.split(rng, 5)\n",
    "  w = 1 + jax.random.normal(rng, shape=[i_size])\n",
    "  x = jax.random.normal(new_rng, shape=[c_size, i_size])\n",
    "  x_querry = jax.random.normal(new_rng2, shape=[1, i_size])\n",
    "\n",
    "  y_data = jnp.squeeze(x@w) + jax.random.normal(new_rng3, shape=[c_size,])*eps_sigma\n",
    "\n",
    "  y_target = x_querry@w + jax.random.normal(new_rng4, shape=[1,])*eps_sigma\n",
    "  y_target = y_target[..., None]\n",
    "\n",
    "\n",
    "  seq = jnp.concatenate([x, y_data[..., None]], -1)\n",
    "  target = jnp.concatenate([x_querry, y_target], -1)\n",
    "  x_querry_init = -1*x_querry.dot(jnp.ones_like(x_querry).T*0.0)\n",
    "  zero = jnp.concatenate([x_querry, x_querry_init], -1)\n",
    "  seq = jnp.concatenate([seq, zero], 0)\n",
    "  return jnp.squeeze(seq), jnp.squeeze(target), w\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(1, 2, 3))\n",
    "def create_data_sin(rng, i_size, c_size, size_distract, input_range, eps_sigma):\n",
    "  \"\"\"Create a linear regression data set: X*w where x ~ N(0, 1), w ~ N(0,1) eps ~ N(0, eps_sigma).\"\"\"\n",
    "\n",
    "  rng, new_rng, new_rng2, new_rng3, new_rng4, new_rng5, new_rng6 = jax.random.split(rng, 7)\n",
    "  w = jax.random.normal(rng, shape=[i_size])\n",
    "\n",
    "  v = jnp.cos(jnp.arange(1,i_size+1) * jnp.pi / 5)\n",
    "  a = jax.random.normal(new_rng, shape=[c_size])\n",
    "  av = jnp.broadcast_to(a, shape=(i_size, c_size)).transpose() * v\n",
    "\n",
    "  u = jnp.sin(jnp.arange(1,i_size+1) * jnp.pi / 5)\n",
    "  b = jax.random.normal(new_rng2, shape=[c_size])\n",
    "  bu = jnp.broadcast_to(b, shape=(i_size, c_size)).transpose() * u\n",
    "\n",
    "  eps = jax.random.normal(new_rng3, shape=[c_size, i_size]) * eps_sigma\n",
    "  x = av + bu + eps\n",
    "\n",
    "  a_q = jax.random.normal(new_rng4, shape=[1])\n",
    "  b_q = jax.random.normal(new_rng5, shape=[1])\n",
    "  eps_q = jax.random.normal(new_rng6, shape=[1, i_size]) * eps_sigma\n",
    "  av_q = jnp.broadcast_to(a_q, shape=(i_size, 1)).transpose() * v\n",
    "  bu_q = jnp.broadcast_to(b_q, shape=(i_size, 1)).transpose() * u\n",
    "\n",
    "  x_querry = av_q + bu_q + eps_q\n",
    "\n",
    "\n",
    "  y_data = jnp.squeeze(x@w)\n",
    "\n",
    "  y_target = x_querry@w\n",
    "  y_target = y_target[..., None]\n",
    "\n",
    "\n",
    "  seq = jnp.concatenate([x, y_data[..., None]], -1)\n",
    "  target = jnp.concatenate([x_querry, y_target], -1)\n",
    "  x_querry_init = -1*x_querry.dot(jnp.ones_like(x_querry).T*0.0)\n",
    "  zero = jnp.concatenate([x_querry, x_querry_init], -1)\n",
    "  seq = jnp.concatenate([seq, zero], 0)\n",
    "  return jnp.squeeze(seq), jnp.squeeze(target), w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data creator\n",
    "data_creator_normal = vmap(create_data_normal,\n",
    "                      in_axes=(0, None, None, None, None, None), out_axes=0)\n",
    "\n",
    "data_creator_noisy = vmap(create_data_normal_noisy,\n",
    "                      in_axes=(0, None, None, None, None, None), out_axes=0)\n",
    "\n",
    "data_creator_sine = vmap(create_data_sin,\n",
    "                      in_axes=(0, None, None, None, None, None), out_axes=0)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Training\n",
    "results =list()\n",
    "config.training_steps = 10000\n",
    "for M in [5, 50,100]:  \n",
    "  for ds_size in [5,10,15,20]:\n",
    "    for e in [0, 0.1, 0.3, 0.5]:\n",
    "      config.dataset_size = ds_size\n",
    "      config.bs = M\n",
    "      # interpolate GD and trained TF\n",
    "      inter = True if (config.deq and not config.use_softmax and config.num_heads == 1) else False\n",
    "\n",
    "      eval_rng = jax.random.PRNGKey(5)\n",
    "      for cur_seed in range(0, config.num_seeds):\n",
    "        config.seed = cur_seed\n",
    "        optimiser, train_state, _, rng = init()\n",
    "        rng, data_rng = jax.random.split(rng, 2)\n",
    "        if config.analyse:\n",
    "          lr_min=0.5\n",
    "\n",
    "    \n",
    "          params_gd = create_weights(config.input_size, \n",
    "                               1, \n",
    "                               config.dataset_size, \n",
    "                               lr_min,\n",
    "                               jax.random.normal(data_rng, shape=[1, 1, config.input_size])*0 ,\n",
    "                               lin_diag=False, \n",
    "                               gd_deq=config.gd_deq,\n",
    "                               num_layers=config.num_layers,\n",
    "                               input_mlp_rnd=rng if (config.input_mlp or config.in_proj) else None,\n",
    "                               in_proj=config.in_proj)\n",
    "          if config.num_layers > 1 or (config.in_proj and config.num_layers == 1):\n",
    "            if cur_seed == 0:\n",
    "              \n",
    "              lr_min=0.5\n",
    "              params_init = create_weights(config.input_size, \n",
    "                                     1, \n",
    "                                     config.dataset_size, lr_min,\n",
    "                                    jax.random.normal(data_rng, shape=[1, 1, config.input_size])*0,\n",
    "                                     lin_diag=True, \n",
    "                                     gd_deq=config.gd_deq,\n",
    "                                     num_layers=config.num_layers,\n",
    "                                    input_mlp_rnd=eval_rng if (config.input_mlp or config.in_proj) else None,\n",
    "                                    in_proj=config.in_proj)\n",
    "              \n",
    "              params_gd_trained, data_rng = pre_train_gd_hps(eval_rng, params_init)\n",
    "          else:\n",
    "             params_gd_trained = params_gd\n",
    "\n",
    "        eval_data = data_creator_sine(jax.random.split(eval_rng, num=1),\n",
    "                                 config.input_size,\n",
    "                                 config.dataset_size,\n",
    "                                 config.size_distract,\n",
    "                                 config.input_range,\n",
    "                                 e)\n",
    "        if config.analyse:\n",
    "          loss_gd, _, _ = predict_test.apply(params_gd, eval_rng, eval_data,True)\n",
    "          loss_gd_trained, _, _ = predict_test.apply(params_gd_trained, eval_rng,\n",
    "                                                eval_data, True)    \n",
    "        original_data_rng = data_rng   \n",
    "        for step in range(config.training_steps):\n",
    "          if config.cycle_data > 0:\n",
    "            if step % config.cycle_data == 0:\n",
    "              data_rng = original_data_rng\n",
    "\n",
    "          rng, data_rng = jax.random.split(data_rng, 2)\n",
    "          train_data = data_creator_sine(jax.random.split(rng, num=config.bs), \n",
    "                              config.input_size,\n",
    "                              config.dataset_size,\n",
    "                              config.size_distract,\n",
    "                              config.input_range,\n",
    "                              e)\n",
    "          train_state, metrics = update(train_state, train_data, optimiser)\n",
    "          \n",
    "        loss_trans, _, _ = predict_test.apply(train_state.params, eval_rng,\n",
    "                                            eval_data, False)\n",
    "      results.append([M, ds_size, e, loss_gd.tolist(), loss_trans.tolist()])\n",
    "          #loss_trans_list[cur_seed].append(loss_trans)\n",
    "          #loss_trans_train_list[cur_seed].append(metrics['train_loss'].item(),)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results, columns = ['M', 'ds_size', 'e', 'loss_gd', 'loss_trained'])\n",
    "results_df.to_csv('results_lin_att_20240402_sine.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
